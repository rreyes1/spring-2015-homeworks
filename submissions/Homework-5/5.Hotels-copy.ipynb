{
 "metadata": {
  "name": "",
  "signature": "sha256:6e0d71ec7dbbfdb558dbb31c4484a4f270adc94a830ad8f37e13403945c4cb48"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(In order to load the stylesheet of this notebook, execute the last code cell in this notebook)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Analyzing hotel ratings on Tripadvisor"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this homework we will focus on practicing two techniques: web scraping and regression. For the first part, we will build upon the sample code from the Lecture and attempt to get some basic information for each hotel. Then, we will fit a regression model on this information and try to analyze it.   "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One of the main disadvantages of scraping a website instead of using an API is that, without any notice, the website may change its layout and render our code useless. Something like that happened in our case. Tripadvisor changed the layout of the buttons that we use to navigate between the different pages of the results. This was the main reason people were having problem with executing the code."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Task 1 (20 pts)**\n",
      "\n",
      "The first task of the homework is to fix the scraping code. We basically need to replace the part where we are checking if there is another page and getting its link with new code that reflects the new navigation layout. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Task 2 (30 pts)**\n",
      "\n",
      "Then, for each hotel that our search returns, we will \"click\" (with the code of course) on it and scrape the information below.\n",
      "\n",
      "![Information to be scraped](hotel_info.png)\n",
      "\n",
      "Of course, feel free to collect even more data if you want. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Task 3 (20 pts) **\n",
      "\n",
      "Now, we will use regression to analyze this information. First, we will fit a linear regression model that predicts the average rating. For example, for the hotel above, the average rating is\n",
      "\n",
      "$$ \\text{AVG_SCORE} = \\frac{1*31 + 2*33 + 3*98 + 4*504 + 5*1861}{2527}$$\n",
      "\n",
      "Use the model to analyze the important factors that decide the $\\text{AVG_SCORE}$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Task 4 (30 pts) **\n",
      "\n",
      "Finally, we will use logistic regression to decide if a hotel is _excellent_ or not. We classify a hotel as _excellent_ if more than **60%** of its ratings are 5 stars. This is a binary attribute on which we can fit a logistic regression model. As before, use the model to analyze the data.\n",
      "\n",
      "-------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to use code from a Python script file, we need to put that file in the same folder as the notebook and import it as a library. Then, we will be able to access it's functions. For example, in the case of the lecture code, we could do the following:\n",
      "\n",
      "``` python\n",
      "import scrape_solution as scrape\n",
      "\n",
      "scrape.get_city_page()\n",
      "```\n",
      "\n",
      "Of course, you might need to modify and restructure the code so that it returns what you need."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "----"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "import time\n",
      "import argparse\n",
      "import logging\n",
      "import requests\n",
      "from BeautifulSoup import BeautifulSoup\n",
      "from collections import defaultdict  # available in Python 2.5 and newer\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parse_hotellist_page(html1):\n",
      "    soup = BeautifulSoup(html1)\n",
      "    hotel_boxes = soup.findAll('div', {'class' :'listing wrap reasoning_v5_wrap jfy_listing p13n_imperfect'})\n",
      "    if not hotel_boxes:\n",
      "        hotel_boxes = soup.findAll('div', {'class' :'listing_info jfy'})\n",
      "    if not hotel_boxes:\n",
      "        hotel_boxes = soup.findAll('div', {'class' :'listing easyClear  p13n_imperfect'})\n",
      "    for hotel_box in hotel_boxes:\n",
      "        hotel_name = hotel_box.find(\"a\", {\"target\" : \"_blank\"}).find(text=True)\n",
      "#        print(\"Hotel name: %s\" % hotel_name.strip())\n",
      "        stars = hotel_box.find(\"img\", {\"class\" : \"sprite-ratings\"})\n",
      "        n_stars = stars['alt'].split()[0]\n",
      "#        if stars:\n",
      "#            print(\"Stars: %s\" % stars['alt'].split()[0])\n",
      "        num_reviews = hotel_box.find(\"span\", {'class': \"more\"}).findAll(text=True)\n",
      "        n_reviews = [x for x in num_reviews if \"review\" in x][0].strip()\n",
      "#        if num_reviews:\n",
      "#            print(\"Number of reviews: %s \" % [x for x in num_reviews if \"review\" in x][0].strip())\n",
      "        if hotel_name.strip() in hotel_names:\n",
      "            print \"duplicate\"\n",
      "\n",
      "        hotel_names[hotel_name.strip()] = n_stars, n_reviews"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 226
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_page_links(html1):\n",
      "    soup = BeautifulSoup(html1)\n",
      "    count_div= soup.find(\"div\", {\"class\":\"orphan   hotelsCount\"})\n",
      "    count = count_div.contents[1].string\n",
      "    div = soup.find(\"div\", {\"class\" : \"pgLinks\"}) # or pgLinks\n",
      "    # check if this is the last page\n",
      "    if div.find('span', {'class' : 'guiArw pageEndNext'}):\n",
      "        return ;\n",
      "        print \"we reached the end\"\n",
      "    else:\n",
      "        hrefs_html = div.findAll('a', href= True)\n",
      "        hrefs = set()\n",
      "        for href in hrefs_html:\n",
      "            link = href['href']\n",
      "            hrefs.add(link)\n",
      "        return hrefs, count\n",
      "url1 = \"http://www.tripadvisor.com/Hotels-g60745-Boston_Massachusetts-Hotels.html#ACCOM_OVERVIEW\"\n",
      "user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.76 Safari/537.36\"\n",
      "headers = {'User-Agent': user_agent}\n",
      "response = requests.get(url1, headers=headers)\n",
      "html = response.text.encode('utf-8')\n",
      "get_page_links(html)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n"
       ]
      }
     ],
     "prompt_number": 245
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "city = \"bosotn\"\n",
      "state = \"massachusetts\"\n",
      "base_url = \"http://www.tripadvisor.com/Hotels\"\n",
      "#url = base_url + \"city=\" + city + \"&state=\" + state\n",
      "url1 = \"http://www.tripadvisor.com/Hotels-g60745-Boston_Massachusetts-Hotels.html#ACCOM_OVERVIEW\"\n",
      "user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.76 Safari/537.36\"\n",
      "headers = {'User-Agent': user_agent}\n",
      "response = requests.get(url1, headers=headers)\n",
      "html = response.text.encode('utf-8')\n",
      "hotel_names = {}\n",
      "hrefs,count = get_page_links(html)\n",
      "print count\n",
      "hrefs.add(\"/Hotels-g60745-Boston_Massachusetts-Hotels.html#ACCOM_OVERVIEW\")\n",
      "for i in hrefs:\n",
      "    url = base_url + i\n",
      "    print url\n",
      "    response = requests.get(url, headers=headers)\n",
      "    time.sleep(2)\n",
      "    html = response.text.encode('utf-8')\n",
      "    if response != 200:\n",
      "        print \"not 200\"\n",
      "        html = response.text.encode('utf-8')\n",
      "    parse_hotellist_page(html)\n",
      "print len(hotel_names)\n",
      "for i in hotel_names:\n",
      "    print i, hotel_names[i]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Hotels-g60745-oa30-Boston_Massachusetts-Hotels.html#ACCOM_OVERVIEW\n"
       ]
      },
      {
       "ename": "AttributeError",
       "evalue": "'unicode' object has no attribute 'add'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-246-638c9a77feec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mhrefs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_page_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mhrefs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Hotels-g60745-Boston_Massachusetts-Hotels.html#ACCOM_OVERVIEW\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhrefs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_url\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAttributeError\u001b[0m: 'unicode' object has no attribute 'add'"
       ]
      }
     ],
     "prompt_number": 246
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dict1 = {}\n",
      "dict1['hotel name'] = 3,12\n",
      "print dict1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'hotel name': (3, 12)}\n"
       ]
      }
     ],
     "prompt_number": 196
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_hotellist_page(city_url, page_count):\n",
      "    url = base_url + city_url\n",
      "    time.sleep(2)\n",
      "    # Request page\n",
      "    headers = { 'User-Agent' : user_agent }\n",
      "    response = requests.get(url, headers=headers)\n",
      "    html = response.text.encode('utf-8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "soup = BeautifulSoup(html)\n",
      "soup.findAll('a');\n",
      "\n",
      "#hotels = set();\n",
      "hotels = defaultdict(int)\n",
      "names = set()\n",
      "\n",
      "for link in soup.findAll('a'):\n",
      "    href = link.get('href')\n",
      "    href = str(href)\n",
      "    if href.find('Reviews') > 27: #hardcode, hotels in \n",
      "        hotels[href] += 1\n",
      "\n",
      "for i in hotels:\n",
      "    if hotels[i] >= 2: #hardcode, \n",
      "        #        print i[ix_start:ix_end]\n",
      "#ex: Hotel_Review-g60745-d121009-Reviews-Holiday_Inn_Express_Boston-Boston_Massachusetts.html\n",
      "        ix_start = i.find('Reviews-') + len('Reviews-')\n",
      "        ix_end = i.find('-Boston_Mass')\n",
      "        names.add(i[ix_start:ix_end].replace(\"_\",\" \"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in names:\n",
      "    print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Colonnade Hotel\n",
        "Residence Inn by Marriott Boston Harbor on Tudor Wharf\n",
        "The Boston Common Hotel and Conference Center\n",
        "DoubleTree Club by Hilton Hotel Boston Bayside\n",
        "Boston Hotel Buckminster\n",
        "Ramada Boston\n",
        "Chandler Inn\n",
        "Mandarin Oriental Boston\n",
        "Hilton Boston Logan Airport\n",
        "XV Beacon\n",
        "Hyatt Regency Boston\n",
        "Newbury Guest House\n",
        "Hotel 140\n",
        "Club Quarters Boston\n",
        "DoubleTree by Hilton Hotel Boston Downtown\n",
        "Battery Wharf Hotel Boston Waterfront\n",
        "DoubleTree Suites by Hilton Boston Cambridge\n",
        "Ames Boston Hotel\n",
        "Boston Marriott Copley Place\n",
        "Eliot Hotel\n",
        "Four Seasons Hotel Boston\n",
        "Charlesmark Hotel\n",
        "Hilton Boston Downtown Faneuil Hall\n",
        "Boston Marriott Long Wharf\n",
        "BEST WESTERN University Hotel Boston Brighton\n",
        "The Westin Boston Waterfront\n",
        "Hampton Inn Suites Boston Crosstown Center\n",
        "Onyx Hotel a Kimpton Hotel\n",
        "Copley House\n",
        "Residence Inn Boston Downtown Seaport\n"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Code for setting the style of the notebook\n",
      "from IPython.core.display import HTML\n",
      "def css_styling():\n",
      "    styles = open(\"../../theme/custom.css\", \"r\").read()\n",
      "    return HTML()\n",
      "#    return HTML(styles)\n",
      "css_styling()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<IPython.core.display.HTML at 0x104394790>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'default' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-27-8f422112d1e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstyles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'default' is not defined"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}